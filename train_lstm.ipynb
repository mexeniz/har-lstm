{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa14934d",
   "metadata": {},
   "source": [
    "# LSTM Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import FeatUtils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme(style=\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f9ef5",
   "metadata": {},
   "source": [
    "# 1. Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1792ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"./data/\"\n",
    "group = \"train\"\n",
    "X, y = FeatUtils.load_dataset_group(group, prefix)\n",
    "# Decrease label's value by one to match the index of prediction outputs\n",
    "y[\"label\"] = y[\"label\"] - 1\n",
    "\n",
    "# Show class stat\n",
    "n_row = len(y)\n",
    "for i in np.unique(y):\n",
    "    n_label = len(y.loc[y[\"label\"] == i])\n",
    "    print(f\"Class {i}: {n_label} rows {(n_label / n_row) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = FeatUtils.make_train_valid_test_feature(\n",
    "    X, y, prep_func=None, split_frac=split_frac)\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"Train set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_valid.shape)\n",
    "print(\"Test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "batch_size = 16\n",
    "train_loader, valid_loader, test_loader = FeatUtils.make_dataloaders(X_train, X_valid, X_test, y_train, y_valid, y_test, batch_size=batch_size)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print(\"Sample input size: \", sample_x.size()) # batch_size, seq_length, input_size\n",
    "print()\n",
    "print(\"Sample label size: \", sample_y.size()) # batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37bcca",
   "metadata": {},
   "source": [
    "# 2. Define Network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import HarLSTM, ModelUtils\n",
    "\n",
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "input_size = 9\n",
    "output_size = len(np.unique(y))\n",
    "n_hidden = 128\n",
    "n_layers = 2\n",
    "\n",
    "# training params\n",
    "epochs = 50\n",
    "lr=0.0001\n",
    "\n",
    "net = HarLSTM(input_size, output_size, n_hidden=n_hidden, n_layers=n_layers)\n",
    "\n",
    "print(\"Model information:\")\n",
    "print(net)\n",
    "\n",
    "# loss and optimization functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d1b5b",
   "metadata": {},
   "source": [
    "# 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b210af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat_dict = ModelUtils.train_net(net, criterion, optimizer, train_loader, valid_loader, batch_size, epochs, \n",
    "                            train_on_gpu=train_on_gpu, print_every=100, clip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0927536",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelUtils.plot_loss_chart(train_stat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45343972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "model_path = f\"har_lstm_{batch_size}_ep{epochs}.pt\"\n",
    "ModelUtils.save_model_weight(net, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d9c5af",
   "metadata": {},
   "source": [
    "# 4. Test inference by a loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e660e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_net = HarLSTM(input_size, output_size, n_hidden=n_hidden, n_layers=n_layers)\n",
    "ModelUtils.load_model_weight(loaded_net, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = ModelUtils.test_net(loaded_net, criterion, test_loader, batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe61e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
