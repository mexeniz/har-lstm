{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69d61d7",
   "metadata": {},
   "source": [
    "# Train LSTM Model by MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import re\n",
    "\n",
    "from loguru import logger\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from models import HarLSTM, ModelUtils\n",
    "from pl_data import HarDataModule\n",
    "from utils import FeatUtils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme(style=\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a92e14",
   "metadata": {},
   "source": [
    "# 1. Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = \"./data/har_dataset\"\n",
    "batch_size = 16\n",
    "data_module = HarDataModule(data_dir_path, \n",
    "                            batch_size=batch_size,\n",
    "                           normalize=\"std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b044d",
   "metadata": {},
   "source": [
    "# 2. Define Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstr_args = ['--max_epochs','10',\n",
    "            '--gpus', '1',\n",
    "             '--batch_size', '16',\n",
    "             '--stochastic_weight_avg', 'True',\n",
    "             '--gradient_clip_val', '5',\n",
    "             '--gradient_clip_algorithm', 'norm',\n",
    "            # DEBUGGING https://pytorch-lightning.readthedocs.io/en/latest/common/debugging.html\n",
    "            # don't forget to turn it off after debugging, slows things down a lot.\n",
    "            # '--profiler', 'pytorch', # issue no.3\n",
    "            # '--log_gpu_memory', 'all',\n",
    "            # '--limit_train_batches', '3',\n",
    "            # '--limit_predict_batches', '3',\n",
    "            # '--overfit_batches', '3',\n",
    "            # Inspect gradient norms\n",
    "            # about 10% performance hit, let's do it always anyway.\n",
    "            # '--track_grad_norm', '2',\n",
    "             ]\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--batch_size', default=16, type=int)\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "args = parser.parse_args(lstr_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ff91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if(use_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "input_size = 9\n",
    "output_size = 6\n",
    "n_hidden = 128\n",
    "n_layers = 2\n",
    "\n",
    "# training params\n",
    "epochs = 50\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HarLSTM(input_size, output_size, n_hidden=n_hidden, n_layers=n_layers)\n",
    "print(\"Model information:\")\n",
    "print(net)\n",
    "trainer = pl.Trainer.from_argparse_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09120525",
   "metadata": {},
   "source": [
    "# 3. Train the model by MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a59b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def log_model_params_step(net):\n",
    "    mlflow.log_param(\"model_type\", type(net))\n",
    "    mlflow.log_param(\"n_layers\", net.n_layers)\n",
    "    mlflow.log_param(\"n_hidden\", net.n_hidden)\n",
    "    mlflow.log_param(\"drop_prob\", net.drop_prob)\n",
    "    mlflow.log_param(\"input_size\", net.input_size)\n",
    "\n",
    "def save_scaler_step(scaler, scaler_path=\"scaler.pkl\"):\n",
    "    FeatUtils.save_feat_scaler(scaler, scaler_path)\n",
    "    mlflow.log_artifact(scaler_path, artifact_path=\"model\")\n",
    "    os.remove(scaler_path)\n",
    "    \n",
    "def test_model_step(net, data_module, batch_size, use_gpu=True):\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    _, test_acc = ModelUtils.test_net(net, net.criterion, test_loader, batch_size, use_gpu=use_gpu)\n",
    "    \n",
    "    mlflow.log_metric(\"acc\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cc36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"HAR_LSTM_Experiment\"\n",
    "mlflow_uri = \"http://mlflow_tracker:5000\"\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(\"Current tracking uri: {}\".format(tracking_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_run_name = \"HAR_LSTM_Training\"\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Train the model\n",
    "with mlflow.start_run(run_name=mlflow_run_name) as run:\n",
    "    artifact_uri = mlflow.get_artifact_uri()\n",
    "    print(\"Current artifact uri: {}\".format(artifact_uri))\n",
    "    \n",
    "    log_model_params_step(net)\n",
    "    \n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"train_val_ratio\", data_module.train_val_ratio)\n",
    "    mlflow.log_param(\"scaler\", type(data_module.scaler) if data_module.scaler is not None else None)\n",
    "    trainer.fit(net, datamodule=data_module)\n",
    "    trainer.test(ckpt_path=\"best\", datamodule=data_module)\n",
    "    \n",
    "    test_model_step(net, data_module, batch_size, use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a10e5",
   "metadata": {},
   "source": [
    "# 4. Test inference by a loaded modelnorm_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_net = HarLSTM(input_size, output_size, n_hidden=n_hidden, n_layers=n_layers)\n",
    "ModelUtils.load_model_weight(loaded_net, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = ModelUtils.test_net(loaded_net, criterion, test_loader, batch_size, use_gpu=use_gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
